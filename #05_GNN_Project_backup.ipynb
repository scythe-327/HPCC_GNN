{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-This note book is the iterartion 05 of the HPCC_GNN_Project-\n",
    "+ we were asked to use the function NPList2Tens which needed the nparray as its parameter along with the correct shape ,\n",
    "  this is just the modified verison of the '#01_GNN_Project_backup'\n",
    "+ To obtain the size of the nparray we are utilizing the np.expanddims "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "import binascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.PngImagePlugin.PngImageFile image mode=P size=2000x1200 at 0x21B894B26E0>\n"
     ]
    }
   ],
   "source": [
    "# img=Image.open(\"C:/Users/rohan/Pictures/Camera Roll/X13_wallpaper_final_16x9_FHD.jpg\")\n",
    "img=Image.open(\"C:/Users/rohan/Pictures/Saved Pictures/img01.png\")\n",
    "print(img)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the image must be opened in read bytes format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279102\n"
     ]
    }
   ],
   "source": [
    "# with open(\"C:/Users/rohan/Pictures/Camera Roll/X13_wallpaper_final_16x9_FHD.jpg\", \"rb\") as image_file:\n",
    "with open(\"C:/Users/rohan/Pictures/Saved Pictures/img01.png\", \"rb\") as image_file:\n",
    "    # image_hex = binascii.hexlify(image_file.read())\n",
    "    print(len(image_file.read()))\n",
    "    # print(image_he\n",
    "    # print(image_hex[:1500])\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the hex data into binary data using unhexlify() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import binascii\n",
    "import pickle\n",
    "binary_data = binascii.unhexlify(image_hex)\n",
    "# header_index = binary_data.find(b'\\xff\\xd8') \n",
    "# stripped_image_bytes = binary_data[header_index:]\n",
    "# stripped_image_hex = binascii.hexlify(stripped_image_bytes)\n",
    "# print(stripped_image_hex)\n",
    "\n",
    "# for i in range(0,15):\n",
    "#     print( binary_data[i])\n",
    "# print(header_index)\n",
    "# with open('C:/Users/rohan/Desktop/uktkjxhcb/HPCC_GNN project backup/pngBinaryDataDump.txt', 'wb') as f:\n",
    "#     pickle.dump(binary_data, f)\n",
    "# f.close();\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if the image data is png we check the first 16 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_signature = \"89504e470d0a1a0a\"\n",
    "if image_hex[:16] == png_signature:\n",
    "    image_hex = image_hex[16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Convert the bytes to a NumPy array \n",
    "# # Interpret a buffer as a 1-dimensional array.\n",
    "\n",
    "\n",
    "# stripped_image_array = np.frombuffer(binary_data, dtype=np.uint8)\n",
    "# np.expand_dims(stripped_image_array,1)\n",
    "# print(stripped_image_array)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method strip_headers(binary_data) using the Pillow library strips the headers from the PNG image.\n",
    "The Image.open() method reads the binary data as an image and automatically strips the headers and metadata to give you a representation of the image data.\n",
    "The image data is then converted to a NumPy array using np.array(). \n",
    "This gives you a NumPy array that only contains the image pixel data, with the headers and metadata stripped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  7  7 ...  2  2  2]\n",
      " [ 7  7  7 ...  2 22 22]\n",
      " [ 7  7  7 ...  2 22 22]\n",
      " ...\n",
      " [ 5 18  5 ... 71 71 71]\n",
      " [ 5  5 18 ... 71 71 71]\n",
      " [ 5  4 18 ... 71 71 71]]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "\n",
    "def strip_headers(binary_data):\n",
    "    with Image.open(BytesIO(binary_data)) as im:\n",
    "        return np.array(im)\n",
    "\n",
    "stripped_image_array1 = strip_headers(binary_data)\n",
    "print(stripped_image_array1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to interpret the binary data as an image and return the image in the form of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 7  7  7 ...  2  2  2]\n",
      " [ 7  7  7 ...  2 22 22]\n",
      " [ 7  7  7 ...  2 22 22]\n",
      " ...\n",
      " [ 5 18  5 ... 71 71 71]\n",
      " [ 5  5 18 ... 71 71 71]\n",
      " [ 5  4 18 ... 71 71 71]], shape=(1200, 2000), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "#use numpyyy\n",
    "#'image' library to strip the headers\n",
    "#reshape by looking into the header\n",
    "import tensorflow as tf\n",
    "image_tensor =tf.convert_to_tensor(stripped_image_array1)\n",
    "print(image_tensor)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is clear that the returned tensor is having a wrong dimensions and thus we can use the np.expanddims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1200, 2000)\n",
      "tf.Tensor(\n",
      "[[[ 7  7  7 ...  2  2  2]\n",
      "  [ 7  7  7 ...  2 22 22]\n",
      "  [ 7  7  7 ...  2 22 22]\n",
      "  ...\n",
      "  [ 5 18  5 ... 71 71 71]\n",
      "  [ 5  5 18 ... 71 71 71]\n",
      "  [ 5  4 18 ... 71 71 71]]], shape=(1, 1200, 2000), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "image_array_with_batch_dim = np.expand_dims(stripped_image_array1, axis=0)\n",
    "print(image_array_with_batch_dim.shape)\n",
    "image_tensor_added_dims =tf.convert_to_tensor(image_array_with_batch_dim)\n",
    "print(image_tensor_added_dims)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REVERTING THE TENSOR BACK TO THE IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  7  7 ...  2  2  2]\n",
      " [ 7  7  7 ...  2 22 22]\n",
      " [ 7  7  7 ...  2 22 22]\n",
      " ...\n",
      " [ 5 18  5 ... 71 71 71]\n",
      " [ 5  5 18 ... 71 71 71]\n",
      " [ 5  4 18 ... 71 71 71]]\n"
     ]
    }
   ],
   "source": [
    "np_ar = image_tensor.numpy()\n",
    "print(np_ar)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nd arrray to bytes\n",
    "bts = np_ar.tobytes()\n",
    "print(bts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'0707070707070707070707071907070707070707070707070707070707070707070707191919190707070719070719191919191919190f191919191919190f0f0f0f0f1b0f0f0f1b0f0f0f0f0f0f0f0f0f0f1b1b1b1b1b1b0a1b0a0a0a0a0a0a0a0a1b0a0a0a0a0a0a0a0a0a0a0a0a0a0a0a0a0a0a0a16161616161616161616161616161616161616161616161616161602020216020202020202020e0202020202020e0e0e0e0e0e0e0e0e0e0e02020e0e0e0e0e1a0e02020e0e0e1a1a1a1a1a1a1a1a1a1a1a1a1313131313131313131355552e2e2e2e2e2e2e2e2c2c2c55131e4545453f453939454545453939452c2e1e453f4b6b21582f5821362121212121216b4444452c2c1e1e2c552e3f4545451e551a0e0e1a1a0e025545453f1436584414144b214b44144b143f1e552c3f550e020e0e1a1a0e1a132e131a0e02160e1a1a1a2e45144444144426266b6b4b215821146b36216b4b4b362121212636365858263621212126582f5836212158582636585826212f58216b213636363921582144212f4b36266b4b21216b216b4b44452c1a02020e1a131a0e132e552e1e3f2e0e1a2e1e1e130e0e1a2c1a160a16161616021a1e45453f4539451e2e45143f2e2e2e552c3921143f1e3f2e0e0e2e2c1e1e2e551e451439393945454545453f4539393f3f3945453f3f39453939452c2c45393f3f453f2c2e131313131a1a13130e020e0e1a0e0e0e0e161b0f0707191b1b0a1b1b19190f0f1b1b0f0f0f1b1b1b0f1b0a1b1b0a161b0f190f0f0f0f1919190f0f0f1907071919191919191919191919191919191919191919191919191907070f0f0f190f0f19191919191919191919190707071919191907070f0f190f0f0f190f0f070719191907070707190f191919191907070707070719191919070707070707190f0f1b1b0a0a1616160a0a16160a160a0a0a0a0a0a0a0a0a0a0a0a1b1b1b1b1b1b1b1b1b1b1b1b1b1b0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f1919191919191919190f19191919191919190f191919191919070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070707070719070707070707070707070707070707070707070707070707070719070707190719070707070707070707070707070707070707'\n"
     ]
    }
   ],
   "source": [
    "# bytes to hex\n",
    "res = binascii.hexlify(bytearray(bts))\n",
    "print(res[:1900])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a tensor\n",
    "tensor = image_tensor\n",
    "\n",
    "# Convert the tensor to a string\n",
    "tensor_str = str(tensor.numpy().tolist())\n",
    "\n",
    "# Write the string to a file\n",
    "with open('C:/Users/rohan/Desktop/uktkjxhcb/HPCC_GNN project backup/pngImgTensorDump.txt', 'w') as f:\n",
    "    f.write(tensor_str)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "serialized_image_tensor = pickle.dumps(image_tensor)\n",
    "\n",
    "with open('C:/Users/rohan/Desktop/uktkjxhcb/HPCC_GNN project backup/pngImgTensorDump.txt', 'wb') as f:\n",
    "    f.write(serialized_image_tensor)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2df843c941f79df9e69f91b658b4d4be4d92f3def93dd0da850d78359da877b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
